### Assumptions of Linear Regression

---

The underlying assumptions of linear regression include:

1. **Linearity**: The relationship between the dependent variable (target) and independent variables (predictors) is linear. The model assumes that changes in the predictors have a constant effect on the target variable.
2. **Independence of Errors**: The errors (residuals) of the model are independent of each other. This means that there should be no correlation between consecutive errors in the data.
3. **Homoscedasticity**: The variance of the errors is constant across all levels of the predictors. In other words, the spread of residuals should be consistent as you move along the range of predictor values.
4. **Normality of Errors**: The residuals are normally distributed. This assumption implies that the errors follow a Gaussian distribution with a mean of zero.
5. **No Multicollinearity**: There should be no multicollinearity among the independent variables. Multicollinearity occurs when two or more predictors are highly correlated with each other, which can cause issues with interpreting individual predictors' effects.